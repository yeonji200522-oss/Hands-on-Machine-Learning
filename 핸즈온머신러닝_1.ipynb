{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIWNXo0DOmvFBqP7KkiF7q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeonji200522-oss/Hands-on-Machine-Learning/blob/main/%ED%95%B8%EC%A6%88%EC%98%A8%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1부 - 머신러닝**\n"
      ],
      "metadata": {
        "id": "wpr8PPByiWEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1장 - 한 눈에 보는 머신러닝**\n"
      ],
      "metadata": {
        "id": "SUVnhsiqiWCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 머신러닝이란?**\n",
        "머신러닝  \n",
        "\n",
        ": 데이터에서 학생하도록 컴퓨터를 프로그래밍하는 과학/예술.  \n",
        "\n",
        ": 명시적인 프로그래밍없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야.\n",
        "\n",
        ": 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것.  \n",
        "(시스템이 학습하는 데 사용한 샘플: 훈련 세트, 각각의 훈련 데이터: 훈련 사례/샘플, 학습하고 예측을 만드는 부분: 모델)  \n",
        "책의 상황일 때 경험 E: 훈련 데이터, 작업 T: 스팸인가 아닌가 구분, 성능측정 P: 사용자 직접 정의 (정확도)"
      ],
      "metadata": {
        "id": "bVtfby8MiV_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 왜 머신러닝을 사용하나요?**  \n",
        "\n",
        "머신러닝은 아래와 같은 분야에서 뛰어남.\n",
        "* 기존 솔루션으로 많은 수동 조정과 규칙이 필요한 문제  \n",
        ": 전통적인 방식보다 머신러닝이 훨씬 코드를 간단하게 만들고 수행함.  \n",
        "\n",
        "* 전통적인 방식으로는 해결 방법이 없는 복잡한 문제  \n",
        ": ex) 음성인식  \n",
        "\n",
        "* 유동적인 환경  \n",
        ": 새로운 데이터로 재훈련이 가능  \n",
        "\n",
        "* 복잡한 문제와 대량의 데이터에서 인사이트 얻기  \n",
        ": 데이터 마이닝: 대용량의 데이터를 분석해 숨겨진 패턴을 발견하는 것.\n"
      ],
      "metadata": {
        "id": "08wrbeIMiV9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3 애플리케이션 사례**  \n",
        "### **1.4 머신러닝 시스템의 종류**  \n",
        "(아래 세 범주는 배타적이지 않아 원하는 대로 연결 가능)\n",
        "* 훈련 지도 방식\n",
        "* 온라인 학습과 배치 방식\n",
        "* 사례 기반 학습과 모델 기반 학습  \n",
        "  \n",
        "  \n",
        "  #### **1.4.1 훈련 지도 방식**  \n",
        "  학습하는 동안의 지도 형태나 정보량에 따라 분류 가능\n",
        "  * 지도 학습: 원하는 답인 레이블이 훈련 데이터에 포함. 분류와 회귀에 초점.  \n",
        "   샘플과 클래스로 훈련을 통한 분류와 특성(예측변수)을 통해 타깃 수치를 예측하는 회귀 작업 수행.  \n",
        "  +회귀 알고리즘을 분류에 사용 가능. ex) 로지스틱 회귀 (: 클래스에 속할 확률)  \n",
        "\n",
        "  * 비지도 학습: 레이블이 훈련 데이터에 미포함. 군집, 차원축소, 이상치탐지에 초점.   \n",
        "  군집 알고리즘, 시각화 알고리즘, 이상치 탐지, 연관규칙학습이 비지도 학습의 예시  \n",
        "\n",
        "  * 준지도 학습: 일부만 레이블이 훈련 데이터에 포함.  \n",
        "  대부분의 준지도 학습 알고리즘은 지도학습과 비지도학습의 조합.  \n",
        "\n",
        "  * 자기 지도 학습: 레이블이 전혀 없는 데이터셋에서 레이블이 완전히 부여된 데이터셋을 생성해 학습. 주로 분류와 회귀에 초점.  \n",
        "  과정에서 필요목적에 맞게 파인튜닝 가능.\n",
        "  \n",
        "  * 강화 학습: 에이전트가 환경을 관찰해서 행동을 실행한 후 보상/벌점을 받아 이후 가장 큰 보상을 얻기 위한 정책을 세우는 학습.\n",
        "\n",
        "  #### **1.4.2 배치 학습과 온라인 학습**\n",
        "  입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지 여부에 따라 분류 가능\n",
        "  * 배치 학습  \n",
        "  오프라인 학습: 먼저 훈련시킨 시스템을 제품 시스템에 적용. 학습시킨 것만 적용 가능.   \n",
        "  시간이 지남에 따라 성능이 저하되는 모델부패/데이터 드리프트 현상 해결을 위해 최신 데이터에서 재훈련 필요. (어떤 모델이냐에 따라 얼마나 자주에 차이)\n",
        "  +데이터의 양이 너무 많거나 자원이 제한된 시스템이 많은 양의 데이터를 스스로 학습해야하는 경우는 다른 알고리즘 사용을 권장.  \n",
        "  \n",
        "  * 온라인 학습  \n",
        "  데이터를 순차적으로 한 개씩 또는 미니배치를 주입해 시스템 훈련. 학습 단계가 빠르고 비용이 적게 드는 것이 장점. 따른 변화에 적응해야하거나 컴퓨팅 자원이 제한된 경우 추천.   \n",
        "  학습률 설정에 따라 속도와 정확도가 변화. 온라인 학습의 가장 큰 단점은 데이터 품질과 학습률에 따라 성능이 감소한다는 점. 해결을 위해 성능 감소가 감지되면 즉각 학습을 중지.  \n",
        "\n",
        "  #### **1.4.3 사례 기반 학습과 모델 기반 학습**\n",
        "  * 일반화: 새로운 데이터에서 좋은 예측을 만들어 내는지.\n",
        "  1. 사례 기반 학습  \n",
        "  일반화: 새 데이터와 학습한 데이터를 비교  \n",
        "  두 데이터 사이의 유사도 측정을 통해 훈련 샘플을 기억하며 학습.  \n",
        "    \n",
        "  2. 모델 기반 학습  \n",
        "  일반화: 샘플들의 모델을 만들어 예측에 사용  \n",
        "  아래는 단순 선형회귀모델 식\n",
        "$$\n",
        "y = \\beta_0 + \\beta_1 x\n",
        "$$\n",
        "  +여기서 베타는 모델 파라미터, X는 특성  \n",
        "\n",
        "  1) 모델 사용 전 모델 파라미터 조정을 통해 측정 지표 설정 필요  \n",
        "  + 호용 함수: 모델이 얼마나 좋은가  \n",
        "  + 비용 함수: 모델이 얼마나 나쁜가 (예측과 훈련 데이터 사이의 거리 측정, 거리를 최소화하는 것이 목표)  \n",
        "  2) 최적의 모델을 찾았다면 이 모델을 사용해 예측  \n",
        "  새 데이터를 위 식에 대입해 원하는 결과를 얻어낼 수 있음.  \n",
        "  3) 산점도를 통한 시각화 및 선형 모델 훈련 예측 과정 코드  \n",
        "```\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#데이터 다운로드 및 준비\n",
        "data_root= \"https://github.com/ageron/data/raw/main\"\n",
        "lifesat=pd.read_csv(data_root + \"/lifesat/lifesat.csv\")\n",
        "x=lifesat[[\"GDP per capita (USD)\"]].values\n",
        "y=lifesat[[\"Life satisfaction\"]].values\n",
        "\n",
        "#데이터 그래프로\n",
        "lifesat.plot(kind=\"scatter\", x=\"GDP per capita (USD)\", y=\"Life satisfaction\")\n",
        "plt.axis([23_500,62_500,4,9])\n",
        "plt.show()\n",
        "\n",
        "#선형 모델 선택\n",
        "model=LinearRegression()\n",
        "\n",
        "#모델 훈련\n",
        "model.fit(x,y)\n",
        "\n",
        "#키프로스에 대해 에측 생성\n",
        "x_new=[[37_655.2]]\n",
        "print(model.predict(x_new))\n",
        "```\n",
        "\n",
        "ex) 각 점을 찍었을 때 가장 가까운 점의 값으로 예측 -> 사례 기반 학습  \n",
        "가까운 K개의 점의 평균 -> K-최근접 이웃 회귀  \n",
        "최근접 이웃 회귀로 바꾸기 위해서는\n",
        "```\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#선형 모델 선택\n",
        "model=LinearRegression()\n",
        "```\n",
        "이부분을  \n",
        "```\n",
        "from sklearn.neighbors import KneighborsRegressor\n",
        "\n",
        "#선형 모델 선택\n",
        "model=KneighborsRegressor(n_neighbors=3)\n",
        "```\n",
        "으로 변경  \n",
        "\n",
        "####<모델 기반 학습 요약>  \n",
        "1. 데이터 분석  \n",
        "2. 모델 선택  \n",
        "3. 훈련 데이터로 모델 훈련 (학습 알고리즘이 비용 함수를 최소화하는 모델 파라미터 탐색)  \n",
        "4. 새로운 데이터에 모델을 적용해 예측 생성 (이 과정을 추론)  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gr-OSis3iV6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1.5 머신러닝의 주요 도전 과제**\n",
        "모델을 훈련시키는 과정에서 나쁜 모델과 나쁜 데이터를 사용 시 문제가 발생  \n",
        "\n",
        "####**1.5.1 충분하지 않은 양의 훈련 데이터**\n",
        "####**1.5.2 대표성 없는 훈련 데이터**\n",
        "대표성이 없는 훈련 데이터를 사용했을 때 정확한 예측을 하지 못하는 문제점이 발생.  \n",
        "* 샘플링 편향: 샘플링 잡음(우연에 의한 대표성 없는 데이터)이 생기고, 매우 큰 샘플들도 추출 방법이 잘못되면 대표성을 띠지 못하는 문제.  \n",
        "\n",
        "####**1.5.3 낮은 품질의 데이터**\n",
        "훈련 데이터가 오류, 이상치, 잡음으로 가득하면 머신러닝 시스템이 내재된 패턴을 찾기 어려워 제대로 작동하지 않음.  \n",
        "훈련 데이터 정제에 많은 시간이 필요한 경우  \n",
        ": 일부 샘플이 이상치인 경우, 해당 샘플 무시 또는 수동으로 수정  \n",
        ": 일부 샘플이 누락된 경우, 특성 전체/일부 무시 또는 임의값으로 대체 및 제외한 모델을 추가로 훈련  \n",
        "\n",
        "####**1.5.4 관련없는 특성**\n",
        "훈련데이터에 관련 있는 특성이 충분해야함.  \n",
        "+ 특성 공학: 특성 선택(훈련에 가장 유용한 특성 선택), 특성 추출(특성을 결합해 더 유용한 특성 생성-차원 축소에 도움), 데이터 수집과 같은 작업을 포함  \n",
        "\n",
        "####**1.5.5 훈련 데이터 과대적합**\n",
        "과도하게 일반화를 하는 과대적합 문제. 훈련데이터에는 잘 맞지만 일반성이 떨어짐.   \n",
        "훈련 데이터의 양과 잡음에 비해 모델이 너무 복잡할 때 발생.  \n",
        "**해결 방법**  \n",
        "+ 파라미터 수가 적은 모델 선정\n",
        "+ 더 많은 훈련 데이터 수집\n",
        "+ 훈련 데이터 잡음 줄이기  \n",
        "훈련 데이터에 가능한 한 가깝게 되도록 직선을 올리거나 내려 평균에 가깝게. 데이터에 완볍ㄱ히 맞추는 것과 일반화를 위해 단순한 모델을 유지하는 것 사이의 올바른 균형을 찾는 것이 중요.  \n",
        "학습하는 동안 적용한 규제의 양은 하이퍼파라미터가 결정. 학습 알고리즘으로부터 영햐으을 받지 않고 훈련 전에 미리 지정, 훈련 동안 상수로 남아있음.  \n",
        "규제 하이퍼파라미터가 크면 평편한 모델, 이 경우 과대적합의 가능성은 낮아지지만 좋은 모델을 찾을 가능성도 낮아짐.  \n",
        "\n",
        "+규제: 모델에 제약을 가하는 것  \n",
        "+자유도: 훈련 데이터에 모델을 맞추기 위한 모델 파라미터.\n",
        "\n",
        "####**1.5.6 훈련 데이터 과소적합**\n",
        "모델이 너무 단순해서 내재된 구조를 학습하지 못할 때 일어나는 문제.  \n",
        "**해결방법**  \n",
        "+ 모델 파라미터가 더 많은 강력한 모델을 선택\n",
        "+ 학습 알고리즘에 더 좋은 특성을 제공 (특성 공학)\n",
        "+ 모델의 제약을 줄이기.\n",
        "\n",
        "####**1.5.7 핵심 요약**"
      ],
      "metadata": {
        "id": "85doQA6PiV23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1.6 테스트와 검증**\n",
        "모델이 새로운 샘플에 얼마나 잘 일반화될지 알 수 있는 방법은 새로운 샘플에 실제로 적용하는 것.  \n",
        "훈련 데이터를 훈련 세트, 테스트 세트로 나눔.  \n",
        "+ 일반화 오차: 새로운 샘플에 대한 오차 비율  \n",
        "테스트 세트에서 모델을 평가해 이 오차에 대한 추정값을 얻음.  \n",
        "훈련오차가 작지만 일반화 오차가 크다면 과대적합되었다는 뜻.  \n",
        "####**1.6.1 하이퍼파라미터 튜닝과 모델 선택**\n",
        " **하이퍼파라미터 값 선정**  \n",
        "N개의 하이퍼파라미터 값으로 N개의 다른 모델을 훈련시키는 방법  \n",
        " **최적의 하이퍼파라미터을 찾았지만 실제에서 성능이 좋지 않을 때**  \n",
        "하이퍼파라미터가 테스트 세트에 최적화된 모델을 생성했기 때문.  \n",
        "**해결방법**   \n",
        "  홀드아웃 검증  \n",
        "  : (과정) 훈련 세트의 일부를 떼어내 여러 후보 모델을 평가하고 가장 좋은 하나 선택. 줄어든 훈련세트에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련. 검증 세트에서 가장 높은 성능을 내는 모델을 선택.  \n",
        "\n",
        "**교차검증**  \n",
        ": 검증 세트가 너무 작으면 모델이 정확하게 평가되지 않아 모델을 잘못 선택할 가능성, 검증 세트가 너무 크면 전체 훈련 세트보다 남은 훈련세트가 커지는 문제 발생 시 방법.  \n",
        ": 검증 새트마다 나머지 데이터에서 훈련한 모델을 해당 검증 세트에서 평가. 하지만 훈련시간이 검증 세트의 개수에 비례해 증가.  \n",
        "\n",
        "####**1.6.2 데이터 불일치**\n",
        "검증 세트와 테스트 세트가 실전에서 기대하는 데이터를 가능한 한 잘 대표해야함.  \n",
        "**해결방법**  \n",
        "훈련-개발 세트  \n",
        ": 훈련 사진의 일부를 떼어내 또 다른 세트를 생성하는 것. 모델이 잘 작동하지 않으면 과대적합된 것. 성능이 나쁘다면 데이터 불일치에서 오는 문제.\n"
      ],
      "metadata": {
        "id": "TJ14cUVriV0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yMGC_DpHC3oN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qUuDbmz6iVyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0RRDD5qGiVwN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaAqvxxgcCt9"
      },
      "outputs": [],
      "source": []
    }
  ]
}